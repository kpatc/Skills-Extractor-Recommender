# ğŸš€ Plateforme Intelligente d'Extraction et Recommandation de CompÃ©tences Techniques

## ğŸ“‹ Vue d'ensemble

Plateforme data-driven complÃ¨te pour l'extraction automatique de compÃ©tences Ã  partir d'offres d'emploi tech marocaines et internationales, avec un systÃ¨me de recommandation basÃ© sur le clustering et le machine learning.

**Module D** - DonnÃ©es AcadÃ©miques et Scientifiques  
**AnnÃ©e**: 2025  
**Groupe**: 3-4 Ã©tudiants

---

## ğŸ¯ Objectifs

- âœ… Scraper et collecter les offres d'emploi tech
- âœ… Extraire automatiquement les compÃ©tences techniques avec NLP
- âœ… Clustering intelligent des profils d'emploi
- âœ… SystÃ¨me de recommandation personnalisÃ©
- âœ… Dashboard interactif pour exploration et analyse
- âœ… Documentation complÃ¨te et rapport acadÃ©mique

---

## ğŸ“‚ Structure du Projet

```
ProjectTD/
â”œâ”€â”€ skill_extractor/                   # ğŸ”§ Module principal
â”‚   â”œâ”€â”€ scrapping/                     # Web scraping
â”‚   â”‚   â”œâ”€â”€ rekrute_scraper.py
â”‚   â”‚   â””â”€â”€ linkedin_scraper.py
â”‚   â”œâ”€â”€ nlp/                          # Traitement du langage
â”‚   â”‚   â”œâ”€â”€ advanced_skills_extractor.py
â”‚   â”‚   â”œâ”€â”€ nlp_pipeline.py
â”‚   â”‚   â””â”€â”€ text_cleaner.py
â”‚   â”œâ”€â”€ modelling/                    # ML & Clustering
â”‚   â”‚   â”œâ”€â”€ clustering.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â””â”€â”€ embeddings.py
â”‚   â”œâ”€â”€ recommendtion/                # Recommandation
â”‚   â”‚   â”œâ”€â”€ clustering_recommender.py
â”‚   â”‚   â”œâ”€â”€ cv_recommender_service.py
â”‚   â”‚   â””â”€â”€ skill_gap.py
â”‚   â”œâ”€â”€ dashboard/                    # ğŸ“Š Streamlit App
â”‚   â”‚   â”œâ”€â”€ app.py                    # Application principale
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ .streamlit/config.toml
â”‚   â”œâ”€â”€ data/                         # ğŸ“Š DonnÃ©es
â”‚   â”‚   â”œâ”€â”€ raw/                      # DonnÃ©es brutes scrapÃ©es
â”‚   â”‚   â”œâ”€â”€ processed/                # DonnÃ©es nettoyÃ©es
â”‚   â”‚   â””â”€â”€ embeddings/               # Embeddings sauvegardÃ©s
â”‚   â”œâ”€â”€ models/                       # ğŸ¤– ModÃ¨les ML sauvegardÃ©s
â”‚   â”œâ”€â”€ process_offers_nlp.py         # Pipeline complet
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ rapport/                           # ğŸ“„ Documentation
â”‚   â”œâ”€â”€ rapport_principal.tex          # Rapport LaTeX complet
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ compile_rapport.sh
â”œâ”€â”€ backend/                           # Backend Django (optionnel)
â””â”€â”€ UI/                               # Frontend React (optionnel)
```

---

## ğŸ—ï¸ Architecture du Pipeline

```
SCRAPING â†’ CLEANING â†’ EXTRACTION â†’ VALIDATION â†’ CLUSTERING â†’ RECOMMENDATION â†’ DASHBOARD
   â†“          â†“          â†“             â†“            â†“              â†“             â†“
ReKrute   Text         Skills        Filter    KMeans/      Scoring        Streamlit
LinkedIn  Cleaning     Extractor      Tech      HDBSCAN      Multi-Criteria  Interface
```

### Ã‰tapes DÃ©taillÃ©es

1. **SCRAPING** ğŸ•·ï¸
   - ReKrute: BeautifulSoup4
   - LinkedIn: Selenium + Browser automation
   - DonnÃ©es: ~250 offres

2. **CLEANING** ğŸ§¹
   - Normalisation texte
   - Tokenization avec spaCy
   - Suppression stopwords

3. **EXTRACTION** ğŸ”
   - Base de 150+ compÃ©tences tech
   - Fuzzy matching (fuzzywuzzy)
   - Validation multi-couche

4. **VALIDATION** âœ…
   - Filtre job tech vs non-tech
   - VÃ©rification compÃ©tence rÃ©elle
   - Score de confiance â‰¥ 0.7

5. **CLUSTERING** ğŸ¯
   - TF-IDF Vectorization
   - KMeans (k=8) ou HDBSCAN
   - Identification profils

6. **RECOMMENDATION** ğŸ’¡
   - SkillMatch: Jaccard similarity
   - ClusterSim: Cosine similarity
   - ProfileFit: CritÃ¨res personnalisÃ©s

7. **DASHBOARD** ğŸ“Š
   - 4 pages Streamlit
   - Visualisations Plotly
   - Filtrage avancÃ©

---

## ğŸš€ DÃ©marrage Rapide

### 1. Installation

```bash
# Cloner/AccÃ©der au projet
cd /home/josh/ProjectTD/skill_extractor

# CrÃ©er environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# ou
.venv\Scripts\activate  # Windows

# Installer dÃ©pendances
pip install -r requirements.txt
```

### 2. DonnÃ©es

Les donnÃ©es sont prÃ©-scrapÃ©es et disponibles dans:
- `data/processed/job_offers_skills_advanced.json` (~250 offres)
- `data/processed/job_offers_essential.json` (format simplifiÃ©)

Pour scraper nouveau:
```bash
python scrapping/rekrute_scraper.py
python scrapping/linkedin_scraper.py
```

### 3. Traitement NLP

```bash
# Pipeline complet
python process_offers_nlp.py
```

Cela va :
- Charger les donnÃ©es JSON
- Appliquer le nettoyage NLP
- Extraire les compÃ©tences
- GÃ©nÃ©rer embeddings
- Sauvegarder les rÃ©sultats

### 4. Lancer le Dashboard

```bash
cd dashboard
pip install -r requirements.txt
streamlit run app.py
```

L'application est accessible sur: **http://localhost:8501**

---

## ğŸ“Š Dashboard Features

### Pages

1. **ğŸ“Š Dashboard** - Vue d'ensemble et mÃ©triques
   - Total offres, compÃ©tences dÃ©tectÃ©es
   - Top 10 compÃ©tences
   - Distribution par source

2. **ğŸ” Extraction** - Explications techniques
   - Pipeline d'extraction dÃ©taillÃ©
   - Techniques NLP utilisÃ©es
   - Base de compÃ©tences

3. **ğŸ’¼ Offres** - Catalogue et recherche
   - Recherche avancÃ©e
   - Filtres (source, compÃ©tences, titre)
   - Affichage dÃ©taillÃ© des offres

4. **ğŸ“ Recommandations** - Matching personnalisÃ©
   - CrÃ©er profil utilisateur
   - SÃ©lectionner compÃ©tences
   - Recommandations avec scoring
   - Visualisation du match

---

## ğŸ“ˆ RÃ©sultats & MÃ©triques

### Performance de l'Extraction

| MÃ©trique | Valeur | Cible | Statut |
|----------|--------|-------|--------|
| PrÃ©cision | 87% | â‰¥85% | âœ… |
| Rappel | 82% | â‰¥80% | âœ… |
| F1-Score | 0.845 | â‰¥0.82 | âœ… |
| Offres tech | 210/250 | - | 84% |
| CompÃ©tences uniques | 152 | - | - |

### Top CompÃ©tences

1. Python - 78 occurrences (37%)
2. JavaScript - 64 (30%)
3. React - 52 (24%)
4. PostgreSQL - 48 (22%)
5. Docker - 46 (21%)
6. AWS - 42 (20%)

### Clusters IdentifiÃ©s

- Cluster 0: Web Developers (React, JS)
- Cluster 1: Backend Engineers (Python, Django)
- Cluster 2: Data Scientists (TensorFlow, Pandas)
- Cluster 3: DevOps/Cloud (Docker, K8s)
- Cluster 4: Full Stack
- Cluster 5: Solutions Architects
- Cluster 6: Mobile Developers
- Cluster 7: QA/Testing

---

## ğŸ”§ Technologies UtilisÃ©es

### Data Collection
- **BeautifulSoup4** - Web scraping
- **Selenium** - JavaScript rendering
- **Requests** - HTTP client

### NLP & Text Processing
- **spaCy** - Tokenization, POS, NER
- **NLTK** - Corpus et resources
- **Transformers (HuggingFace)** - BERT embeddings
- **sentence-transformers** - Semantic embeddings
- **fuzzywuzzy** - Fuzzy string matching
- **unidecode** - Character normalization

### Machine Learning
- **scikit-learn** - KMeans clustering, TF-IDF
- **HDBSCAN** - Density-based clustering
- **numpy, pandas** - Data manipulation

### Data Visualization
- **Streamlit** - Web app framework
- **Plotly** - Interactive charts
- **matplotlib, seaborn** - Static viz

### Storage
- **JSON** - Structured data
- **CSV** - Tabular data
- **Pickle** - Model serialization

---

## ğŸ“„ Rapport AcadÃ©mique

Le rapport complet est disponible dans le dossier `rapport/`:

### Contenu
- ProblÃ©matique et contexte
- Sources de donnÃ©es
- Architecture data dÃ©taillÃ©e
- MÃ©thodes NLP et ML
- RÃ©sultats quantifiÃ©s
- Limitations et futures amÃ©liorations
- Contribution Ã  la transformation digitale

### Compilation

```bash
cd rapport
bash compile_rapport.sh
# ou
pdflatex -interaction=nonstopmode rapport_principal.tex
```

RÃ©sultat: `rapport_principal.pdf` (5-7 pages)

---

## ğŸ” Exploration des DonnÃ©es

### Charger les donnÃ©es

```python
import json
import pandas as pd

# Charger JSON
with open('data/processed/job_offers_skills_advanced.json', 'r') as f:
    offers = json.load(f)

# CrÃ©er DataFrame
df = pd.DataFrame(offers)

# Statistiques
print(f"Total offres: {len(df)}")
print(f"Colonnes: {df.columns.tolist()}")
print(f"CompÃ©tences uniques: {len(set(s for skills in df['skills'] for s in skills))}")
```

### Analyser les compÃ©tences

```python
from collections import Counter

# Compter les compÃ©tences
all_skills = []
for skills in df['skills']:
    all_skills.extend(skills)

skill_counts = Counter(all_skills)
print(skill_counts.most_common(10))
```

---

## ğŸ› ï¸ Development

### Code Structure

```python
# Extraction de compÃ©tences
from nlp.advanced_skills_extractor import SkillsExtractor

extractor = SkillsExtractor()
job_desc = "Looking for Python + React developer..."
skills = extractor.extract_skills(job_desc)
# â†’ ['Python', 'React']
```

```python
# Clustering
from modelling.clustering import SkillsVectorizer, SkillsClusterer

vectorizer = SkillsVectorizer()
embeddings = vectorizer.vectorize_descriptions(offers)

clusterer = SkillsClusterer()
clusters = clusterer.cluster(embeddings, n_clusters=8)
```

```python
# Recommandation
from recommendtion.clustering_recommender import ClusteringRecommender

recommender = ClusteringRecommender(offers, clusters)
recommendations = recommender.recommend(user_skills=['Python', 'Docker'])
```

---

## ğŸ“‹ Checklist de DÃ©veloppement

- âœ… Web Scraping (ReKrute, LinkedIn)
- âœ… NLP Cleaning & Preprocessing
- âœ… Skills Extraction (Advanced)
- âœ… Validation Multi-couche
- âœ… Vectorization & Clustering
- âœ… Recommendation Engine
- âœ… Streamlit Dashboard
- âœ… Rapport acadÃ©mique complet
- âœ… Documentation
- âœ… Code cleanup & organization

---

## ğŸš§ Prochaines AmÃ©liorations

### Court Terme
- [ ] Augmenter dataset Ã  2000+ offres
- [ ] Fine-tuner NER model
- [ ] Ajouter nouvelles sources (Indeed, GitHub Jobs)
- [ ] SystÃ¨me de notation utilisateur

### Moyen Terme
- [ ] API REST (FastAPI/Flask)
- [ ] SystÃ¨me de recommandation collaboratif
- [ ] Email alerts
- [ ] DB (PostgreSQL)

### Long Terme
- [ ] Support multilingue (EN, ES, DE)
- [ ] PrÃ©diction salaires
- [ ] Trend prediction ML
- [ ] App mobile (Flutter)
- [ ] LinkedIn API integration

---

## ğŸ“§ Contact & Support

Pour des questions sur le projet:
- Consulter la documentation: `rapport/README.md`
- Explorer le code: Commentaires dÃ©taillÃ©s dans tous les fichiers
- Tester le dashboard: Lancer l'application Streamlit

---

## ğŸ“œ Licence

Projet acadÃ©mique - AnnÃ©e 2025

---

## ğŸ™ Remerciements

Merci aux sources de donnÃ©es:
- **ReKrute.com** - Offres d'emploi marocaines
- **LinkedIn** - Offres internationales
- **Open Data Communities** - Ressources NLP

---

**DerniÃ¨re mise Ã  jour**: DÃ©cembre 2025  
**Version**: 1.0 - Production Ready  
**Status**: âœ… Complet et documentÃ©
